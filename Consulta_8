#Consulta 8 : Distribución de popularidad por duración de la canción
Ayuda a analizar si las canciones más largas o más cortas tienden a ser más populares. Esto puede dar pistas sobre las preferencias del público y la estructura de la música más comercial.


from pyspark.sql import SparkSession
from dotenv import load_dotenv
import os

#Carga de variables para el entorno
APP_NAME = "Distribucion_Popularidad_Por_Duracion_Cancion"

load_dotenv()

#Se configuran los directorios de entrada y salida respectivamente
INPUT_DIR = str(os.getenv("DATA_DIR"))
OUTPUT_DIR = str(os.getenv("OUTPUT_DIR"))

# Se realiza la sesión de Spark
spark = SparkSession.builder \
    .appName(APP_NAME) \
    .master("yarn") \
    .getOrCreate()

#Se configura la Ruta de entrada y salida
data_dir = INPUT_DIR
output_dir = f"{OUTPUT_DIR}/{APP_NAME}/"

# Se procede con la lectura de datos
df = spark.read.option("header", "true") \
    .option("delimiter", ",") \
    .option("encoding", "latin1") \
    .csv(data_dir)

#Validación de tipos de variables
df = df.withColumn("RANKING", col("RANKING").cast("integer")) \
       .withColumn("DURACION", col("DURACION").cast("float"))

# Se procede a agrupar por duración y calcular el promedio de ranking para cada rango de duración
df_aggregated = df.groupBy("DURACION").agg(spark_avg("RANKING").alias("PROMEDIO_RANKING"))

# Se ordenar los resultados por duración para ver cómo varía el ranking con la duración
df_aggregated = df_aggregated.orderBy("DURACION")

# Se procede a almacenar los resultados en HDFS
df_aggregated.write.mode("overwrite").option("header", "true").csv(output_dir)

# Se muestran los resultados
df_aggregated.show(truncate=False)

# Finaliza sesión
spark.stop()
