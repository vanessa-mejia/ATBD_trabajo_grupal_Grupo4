#COnsulta 5: Tendencias de popularidad por año
Esta consulta permite ver si hay años con una cantidad inusualmente alta de éxitos, lo que podría estar relacionado con eventos culturales, sociales o tecnológicos importantes.


from pyspark.sql import SparkSession
from dotenv import load_dotenv
import os

# Se cargan las variables de entorno
APP_NAME = "Tendencias_Popularidad_Por_Año"

load_dotenv()

# Se crean los directorios de entrada y salida
INPUT_DIR = str(os.getenv("DATA_DIR"))
OUTPUT_DIR = str(os.getenv("OUTPUT_DIR"))

# Se crear la sesión de Spark
spark = SparkSession.builder \
    .appName(APP_NAME) \
    .master("yarn") \
    .getOrCreate()

# Se definen las rutas de entrada y salida
data_dir = INPUT_DIR
output_dir = f"{OUTPUT_DIR}/{APP_NAME}/"

# Se leen los datos desde HDFS
df = spark.read.option("header", "true") \
    .option("delimiter", ",") \
    .option("encoding", "latin1") \
    .csv(data_dir)

# Se validan los tipos de datos 
df = df.withColumn("RANKING", col("RANKING").cast("integer")) \
       .withColumn("AÑO", col("AÑO").cast("integer"))

# Se agrupar por año y contar cuántos éxitos (ranking) ocurrieron en cada año
df_aggregated = df.groupBy("AÑO").agg(spark_count("RANKING").alias("NUMERO_DE_EXITOS"))

# Se ordenar los resultados por año
df_aggregated = df_aggregated.orderBy("AÑO")

# Se almacenar los resultados en HDFS
df_aggregated.write.mode("overwrite").option("header", "true").csv(output_dir)

# Se muestran los resultados
df_aggregated.show(truncate=False)

#  Sesión Finalizada
spark.stop()
